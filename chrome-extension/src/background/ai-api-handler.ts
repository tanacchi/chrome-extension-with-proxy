/**
 * @fileoverview Background Script AI API ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
 *
 * Content Scriptã‹ã‚‰ã®AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡ã—ã€
 * OpenAI APIã¨ã®å®Ÿéš›ã®é€šä¿¡ã‚’è¡Œã„ã¾ã™ã€‚
 * Chromeæ‹¡å¼µæ©Ÿèƒ½ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã«å¾“ã„ã€
 * APIé€šä¿¡ã¯Background Scriptã§é›†ä¸­ç®¡ç†ã•ã‚Œã¾ã™ã€‚
 *
 * @author Chrome Extension Development Team
 * @since 1.0.0
 */

import { createOpenAI } from '@ai-sdk/openai';
import { aiSettingsStorage } from '@extension/storage';
import { generateText } from 'ai';
import type { ChromeMessage, ChromeMessageResponse } from '@extension/ai-api';

/**
 * AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‹å®šç¾©
 *
 * @interface AIAnalysisRequest
 */
interface AIAnalysisRequest {
  /** ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é…åˆ— */
  messages: Array<{ role: string; content: string }>;
  /** AIè¨­å®š */
  settings?: {
    apiKey?: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
  };
}

/**
 * AIåˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‹å®šç¾©
 *
 * @interface AIAnalysisResponse
 */
interface AIAnalysisResponse {
  /** ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ */
  text: string;
  /** ä½¿ç”¨é‡æƒ…å ± */
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  /** å‡¦ç†æ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰ */
  processingTime: number;
}

/**
 * AI API ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹
 *
 * OpenAI APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã—ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨
 * ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’æä¾›ã—ã¾ã™ã€‚
 *
 * @example
 * ```typescript
 * const handler = new AIAPIHandler();
 * handler.initialize();
 * ```
 *
 * @since 1.0.0
 */
export class AIAPIHandler {
  private isInitialized = false;

  /**
   * ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™
   * Chromeæ‹¡å¼µæ©Ÿèƒ½ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒŠãƒ¼ã‚’è¨­å®šã—ã¾ã™
   *
   * @since 1.0.0
   */
  public initialize(): void {
    if (this.isInitialized) {
      console.warn('AI API Handler is already initialized');
      return;
    }

    // Chromeæ‹¡å¼µæ©Ÿèƒ½ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒŠãƒ¼ã‚’è¨­å®š
    chrome.runtime.onMessage.addListener(
      (
        message: ChromeMessage<AIAnalysisRequest>,
        sender: chrome.runtime.MessageSender,
        sendResponse: (response: ChromeMessageResponse<AIAnalysisResponse>) => void,
      ) => {
        // AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã¿ã‚’å‡¦ç†
        if (message.type === 'AI_ANALYSIS_REQUEST') {
          this.handleAIAnalysisRequest(message, sender, sendResponse);
          return true; // éåŒæœŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç¤ºã™
        }
        return false;
      },
    );

    this.isInitialized = true;
    console.log('AI API Handler initialized successfully');
  }

  /**
   * AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¾ã™
   *
   * @param message - Chrome ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
   * @param sender - é€ä¿¡è€…æƒ…å ±
   * @param sendResponse - ãƒ¬ã‚¹ãƒãƒ³ã‚¹é–¢æ•°
   *
   * @private
   */
  private async handleAIAnalysisRequest(
    message: ChromeMessage<AIAnalysisRequest>,
    sender: chrome.runtime.MessageSender,
    sendResponse: (response: ChromeMessageResponse<AIAnalysisResponse>) => void,
  ): Promise<void> {
    const startTime = Date.now();

    try {
      // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼
      if (!message.data || !message.data.messages) {
        throw new Error('Invalid request: messages are required');
      }

      // AIè¨­å®šã®å–å¾—
      const settings = await this.getAISettings(message.data.settings);

      // APIã‚­ãƒ¼ã®æ¤œè¨¼
      if (!settings.apiKey) {
        throw new Error('OpenAI API key is not configured');
      }

      // é–‹ç™ºæ™‚ã¯mock-apiã€æœ¬ç•ªæ™‚ã¯OpenAI APIã‚’ä½¿ç”¨
      const isDevelopment = settings.apiKey === 'sk-test-development-api-key-placeholder';

      let result: {
        text: string;
        usage?: {
          promptTokens: number;
          completionTokens: number;
          totalTokens: number;
        };
      };

      if (isDevelopment) {
        // Mock API ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨
        console.log('AI Analysis: Mock APIã‚µãƒ¼ãƒãƒ¼ä½¿ç”¨ (http://localhost:3001)');
        result = await this.callMockAPI(message.data);
      } else {
        // OpenAI API ã‚’ä½¿ç”¨
        console.log('AI Analysis: OpenAI APIä½¿ç”¨');
        result = await this.callOpenAIAPI(message.data, settings);
      }

      const processingTime = Date.now() - startTime;

      // æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹
      const response: ChromeMessageResponse<AIAnalysisResponse> = {
        success: true,
        data: {
          text: result.text,
          usage: result.usage
            ? {
                promptTokens: result.usage.promptTokens,
                completionTokens: result.usage.completionTokens,
                totalTokens: result.usage.totalTokens,
              }
            : undefined,
          processingTime,
        },
        requestId: message.requestId,
      };

      sendResponse(response);
    } catch (error) {
      const processingTime = Date.now() - startTime;

      console.error('AI Analysis Error:', error, `(Processing time: ${processingTime}ms)`);

      // ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹
      const errorResponse: ChromeMessageResponse<AIAnalysisResponse> = {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error occurred',
        errorCode: this.getErrorCode(error),
        requestId: message.requestId,
      };

      sendResponse(errorResponse);
    }
  }

  /**
   * AIè¨­å®šã‚’å–å¾—ã—ã¾ã™
   * ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è¨­å®šã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®è¨­å®šã‚’ãƒãƒ¼ã‚¸ã—ã¾ã™
   *
   * @param requestSettings - ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å«ã¾ã‚Œã‚‹è¨­å®š
   * @returns ãƒãƒ¼ã‚¸ã•ã‚ŒãŸè¨­å®š
   *
   * @private
   */
  private async getAISettings(requestSettings?: AIAnalysisRequest['settings']) {
    try {
      // ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰åŸºæœ¬è¨­å®šã‚’å–å¾—
      const storedSettings = await aiSettingsStorage.get();

      // ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®šã¨ãƒãƒ¼ã‚¸ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®šãŒå„ªå…ˆï¼‰
      return {
        apiKey: requestSettings?.apiKey || storedSettings.apiKey,
        model: requestSettings?.model || storedSettings.model || 'gpt-4o-mini',
        temperature: requestSettings?.temperature ?? 0.7,
        maxTokens: requestSettings?.maxTokens ?? 1000,
      };
    } catch (error) {
      console.error('Failed to load AI settings:', error);
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
      return {
        apiKey: requestSettings?.apiKey || '',
        model: requestSettings?.model || 'gpt-4o-mini',
        temperature: requestSettings?.temperature ?? 0.7,
        maxTokens: requestSettings?.maxTokens ?? 1000,
      };
    }
  }

  /**
   * é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ç”¨ã®å›ºå®šãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™
   *
   * @param requestData - ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
   * @param settings - AIè¨­å®š
   * @returns é–‹ç™ºç”¨ã®å›ºå®šãƒ¬ã‚¹ãƒãƒ³ã‚¹
   *
   * @private
   */
  private async callMockAPI(requestData: AIAnalysisRequest): Promise<{
    text: string;
    usage?: {
      promptTokens: number;
      completionTokens: number;
      totalTokens: number;
    };
  }> {
    // é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ç”¨ã®å›ºå®šãƒ¬ã‚¹ãƒãƒ³ã‚¹
    const mockAnalysisResult = this.generateMockAnalysisResult(requestData.messages);

    // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ç°¡æ˜“è¨ˆç®—ï¼ˆæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
    const inputText = requestData.messages.map(m => m.content).join(' ');
    const promptTokens = Math.ceil(inputText.length / 4); // å¤§ä½“4æ–‡å­—ã§1ãƒˆãƒ¼ã‚¯ãƒ³
    const completionTokens = Math.ceil(mockAnalysisResult.length / 4);

    // å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã‚’æ¨¡å€£ã™ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
    await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 200));

    return {
      text: mockAnalysisResult,
      usage: {
        promptTokens,
        completionTokens,
        totalTokens: promptTokens + completionTokens,
      },
    };
  }

  /**
   * é–‹ç™ºç”¨ã®ãƒ¢ãƒƒã‚¯åˆ†æçµæœã‚’ç”Ÿæˆã—ã¾ã™
   *
   * @param messages - å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
   * @returns ãƒ¢ãƒƒã‚¯åˆ†æçµæœ
   *
   * @private
   */
  private generateMockAnalysisResult(messages: Array<{ role: string; content: string }>): string {
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’æŠ½å‡º
    const userMessage = messages.find(m => m.role === 'user')?.content || '';

    // ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    const hasTableData =
      userMessage.includes('\t') ||
      userMessage.includes('|') ||
      userMessage.toLowerCase().includes('table') ||
      userMessage.toLowerCase().includes('ãƒ†ãƒ¼ãƒ–ãƒ«');

    if (hasTableData) {
      return `ğŸ“Š **AIåˆ†æçµæœï¼ˆé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼‰**

ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åˆ†æçµæœï¼š

ğŸ” **ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´**
- ãƒ‡ãƒ¼ã‚¿å½¢å¼: æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡º
- é …ç›®æ•°: è¤‡æ•°ã®ã‚«ãƒ©ãƒ ã¨è¡Œã§æ§‹æˆ
- ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡: æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¨æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ãŒæ··åœ¨

ğŸ“ˆ **å‚¾å‘ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³**
- ãƒ‡ãƒ¼ã‚¿ã«ã¯ä¸€å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã‚‰ã‚Œã¾ã™
- å„é …ç›®é–“ã«ç›¸é–¢é–¢ä¿‚ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã¯æ¯”è¼ƒçš„å‡ç­‰ã§ã™

ğŸ’¡ **æ¨å¥¨äº‹é …**
- ã‚ˆã‚Šè©³ç´°ãªåˆ†æã«ã¯è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ãŒæœ‰åŠ¹ã§ã™
- ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™
- å®šæœŸçš„ãªãƒ‡ãƒ¼ã‚¿æ›´æ–°ã§å‚¾å‘ã‚’è¿½è·¡ã§ãã¾ã™

âš ï¸ *ã“ã‚Œã¯é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ç”¨ã®å›ºå®šãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚å®Ÿéš›ã®åˆ†æã«ã¯æœ¬ç•ªã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚*`;
    } else {
      return `ğŸ¤– **AIå¿œç­”ï¼ˆé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼‰**

ã”è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ï¼š

ğŸ“ **å›ç­”å†…å®¹**
å…¥åŠ›ã„ãŸã ã„ãŸå†…å®¹ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰å›ç­”ã„ãŸã—ã¾ã™ï¼š

â€¢ åŸºæœ¬çš„ãªæƒ…å ±æ•´ç†
â€¢ é–¢é€£ã™ã‚‹è¦ç´ ã®ç‰¹å®š
â€¢ æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ğŸ¯ **è¦ç‚¹**
- å†…å®¹ã‚’ç†è§£ã—ã€é©åˆ‡ãªå¯¾å¿œã‚’æ¤œè¨ã—ã¾ã—ãŸ
- ã•ã‚‰ãªã‚‹è©³ç´°ãŒå¿…è¦ãªå ´åˆã¯ãŠçŸ¥ã‚‰ã›ãã ã•ã„
- ç¶™ç¶šçš„ãªã‚µãƒãƒ¼ãƒˆãŒå¯èƒ½ã§ã™

âš ï¸ *ã“ã‚Œã¯é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ç”¨ã®å›ºå®šãƒ¬ã‚¹ãƒãƒ³ã‚¹ã§ã™ã€‚å®Ÿéš›ã®AIåˆ†æã«ã¯æœ¬ç•ªã®APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚*`;
    }
  }

  /**
   * OpenAI API ã‚’å‘¼ã³å‡ºã—ã¾ã™
   *
   * @param requestData - ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
   * @param settings - AIè¨­å®š
   * @returns OpenAI API ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
   *
   * @private
   */
  private async callOpenAIAPI(
    requestData: AIAnalysisRequest,
    settings: {
      apiKey: string;
      model: string;
      temperature: number;
      maxTokens: number;
    },
  ): Promise<{
    text: string;
    usage?: {
      promptTokens: number;
      completionTokens: number;
      totalTokens: number;
    };
  }> {
    const openai = createOpenAI({
      apiKey: settings.apiKey, // å®Ÿéš›ã®OpenAI APIã‚­ãƒ¼
    });

    const model = openai(settings.model);

    return await generateText({
      model: model,
      messages: requestData.messages.map(msg => ({
        role: msg.role as 'system' | 'user' | 'assistant',
        content: msg.content,
      })),
      temperature: settings.temperature,
      maxTokens: settings.maxTokens,
    });
  }

  /**
   * ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™
   *
   * @param error - ã‚¨ãƒ©ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
   * @returns ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
   *
   * @private
   */
  private getErrorCode(error: unknown): string {
    if (error instanceof Error) {
      const message = error.message.toLowerCase();
      // OpenAI API ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡
      if (message.includes('api key')) {
        return 'INVALID_API_KEY';
      }
      if (message.includes('rate limit')) {
        return 'RATE_LIMIT_EXCEEDED';
      }
      if (message.includes('quota')) {
        return 'QUOTA_EXCEEDED';
      }
      if (message.includes('network') || message.includes('fetch')) {
        return 'NETWORK_ERROR';
      }
    }
    return 'UNKNOWN_ERROR';
  }

  /**
   * ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
   *
   * @returns åˆæœŸåŒ–æ¸ˆã¿ã‹ã©ã†ã‹
   *
   * @since 1.0.0
   */
  public isReady(): boolean {
    return this.isInitialized;
  }

  /**
   * ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã—ã¾ã™
   * ãƒªã‚¹ãƒŠãƒ¼ã‚’å‰Šé™¤ã—ã€ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™
   *
   * @since 1.0.0
   */
  public shutdown(): void {
    if (!this.isInitialized) {
      return;
    }

    // ãƒªã‚¹ãƒŠãƒ¼ã®å‰Šé™¤
    // Note: chrome.runtime.onMessage.removeListener ã¯ç‰¹å®šã®ãƒªã‚¹ãƒŠãƒ¼é–¢æ•°ãŒå¿…è¦
    // å®Ÿè£…ä¸Šã¯é€šå¸¸æ‹¡å¼µæ©Ÿèƒ½ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«çµ‚äº†æ™‚ã«è‡ªå‹•çš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹

    this.isInitialized = false;
    console.log('AI API Handler shutdown completed');
  }
}

/**
 * ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
 */
export const aiAPIHandler = new AIAPIHandler();
